---
title: "ANOVA: Part 2"
author: "Dr. Jacob C. Cooper"
format: html
editor: visual
---

## Two-way ANOVA

Previously, we discussed one-way ANOVAs, where we are looking at a single factor split across three or more groups and trying to determine if the means of these groups are equal (*i.e.*, $H_0: \mu_1=\mu_2=...\mu_i$). ANOVA specifically allows us to analyze the variance of these different groups to ascertain which factors are most responsible for the variation we observe in the data. Because of the way ANOVA operates, we can actually test multiple different combinations of variables simultaneously in what we call a *two-way ANOVA*.

Don't forget to load your required packages - some we have used before, like `agricolae`, `plyr`, and `tidyverse`, but others are new for this section: `multcomp` and `nlme`! As a reminder, these packages are designed for the following:

-   `agricolae`: originally written as a Master's thesis at the Universidad Nacional de Ingeniería (Lima, Perú), this package is designed to help with agricultural research.
-   `plyr`: tools for common problems, including splitting data, applying functions across data, and combining datasets together.
-   `tidyverse`: one we are already familiar with; a wrapper for installing `ggplot2`, `dplyr`, `tidyr`, `readr`, `purrr`, `tibble`, `stringr`, and `forcats`.
-   `multcomp`: more in depth and better **MULT**iple **COMP**arisons via linear models and related models.
-   `nlme`: a package for fitting Gaussian and **n**on-**l**inear **m**ixed-**e**ffect models.

```{r, message = F}
library(agricolae)
library(plyr)
library(tidyverse)

# NEW PACKAGES NEEDED
library(multcomp)
library(nlme)
```

## Designs

There are several different designs for two-way ANOVAs, and we will cover some of the most common designed here.

### Randomized block design

Randomized block designs look at combinations of variables that could be affecting the results. More specifically, we are looking at two *strata* or *factors* and their effects on a *continuous* response variable. (As a random aside, Bíldudalur is home to one of my wife's favorite places to visit: The Icelandic Sea Monster Museum and Coffee Shop).

Quick pronunciation guide to these locations: the letter "ð" (*eth*) is pronounced like a light "*th*" in English, or like a "*d*" in Spain Spanish like in the last "d" in *Madrid*. Accents indicate a letter gets more emphasis, while umlauts (*i.e.*, ö) indicate a slightly different pronunciation and tone, and often indicate that vowels should be pronounced separately and not together (*i.e.*, "naïve" in English). The letter "þ" (*thorn*) is the letter for a hard "*th*" sound, as in "*thorn*" ("*þorn*"). þ was a letter in the English alphabet, and was used extensively in words like *the* (*þe*), but the letter was obsoleted by the printing press. German printers, who don't have a "*th*" in their language, did not have *þ* on their presses. Before the invention of *th* for the sound, the printers would substitute *y* as an approximation. Hence, when you see "*Ye Olde Shoppe*", this should actually be "*Þe Olde Shoppe*" and thus pronounced like "*the*". While this letter was lost in English, it still exists in Icelandic. Hence, the locations below are approximately pronounced as:

-   Tálknafjörður - *TALK-na-fyorther*

-   Bíldudalur - *BEEL-du-da-lur*

-   Þingeyri - *Thin-ghey-rey*

```{r}
set.seed(8675309)

# average fish size in relation to location in Iceland and food used

location <- c("Tálknafjörður", "Bíldudalur", "Þingeyri")

food <- c("SuperFood", "Gigachad Fish Food", "MegaFish Flakes")

fish_sizes <- c(10.1,12.6,11.2,
                9.4,11.0,10.1,
                12.3,15.4,11.9)

data_expanded <- matrix(data = fish_sizes, ncol = 3, byrow = TRUE)

rownames(data_expanded) <- location

colnames(data_expanded) <- food

data_expanded
```

*Note* that this table is in the format that we most often see, but we need to reshape these data to make it easier for us to perform our analyses. I created the data here as a matrix with named columns and rows; the following code may need to be adjusted if you do things differently.

```{r}
# expand to "long" format
data <- data_expanded %>%
  # convert to data frame
  as.data.frame() %>%
  # create new column to account for row names
  # may not be needed, depending on your data format
  mutate(Location = rownames(data_expanded)) %>%
  # !by column for aggregating
  # names_to = what to name column aggregation
  # values_to = what the measurements should be called
  pivot_longer(!Location, names_to = "Food", values_to = "Size")

data
```

Now we can do our ANOVA. ***Note*** that I put `factor` around the blocking variable.

```{r}
data_aov <- aov(Size ~ Food + factor(Location), data)

summary(data_aov)
```

As we can see above, both `Location` and `Food` have a significant effect on the size of the fish in our study. Now, we need to figure out the groupings and plot our results.

Unfortunately, the `agricolae` function `HSD.test` does not work as well for these multi-directional ANOVAs.

```{r}
tukey_data_aov <- TukeyHSD(data_aov)

tukey_data_aov
```

Note above that we have the different factors that we are analyzing - location and food - and we have to look at these means independently. Unfortunately, we do have to assess the means ourselves.

```{r}
sig_levels_locations <- matrix(data = c("Tálknafjörður", "AB",
                                        "Bíldudalur", "A",
                                        "Þingeyri", "B"), 
                               byrow = T, ncol = 2) %>% as.data.frame()

# make labels match!
colnames(sig_levels_locations) <- c("Location", "significance")

sig_levels_food <- matrix(data = c("MegaFish Flakes", "AB",
                                   "Gigachad Fish Food", "A",
                                   "SuperFood", "B"),
                          byrow = T, ncol = 2) %>% as.data.frame()

# make labels match!
colnames(sig_levels_food) <- c("Food", "significance")
```

Now, we can plot these different factors.

```{r}
# summarize by group
gg_data_location <- ddply(data, "Location", summarise,
                          N = length(Size),
                          mean = mean(Size),
                          sd = sd(Size),
                          se = sd / sqrt(N))

gg_data_food <- ddply(data, "Food", summarise,
                      N = length(Size),
                      mean = mean(Size),
                      sd = sd(Size),
                      se = sd / sqrt(N))
```

```{r}
# Location

ggplot(gg_data_location, # plot summary data
       # Define plotting - x by group, y is mean, grouping by group
       aes(x = Location, y = mean, group = Location)) +
  # add points to plot for y values
  geom_point() +
  # add error bars around points
  geom_errorbar(data = gg_data_location, 
                # define error bars
                aes(ymin = mean - 2*se, ymax = mean+2*se,
                    # define color, size
                                    color = Location), width = 0.1) +
  # set vertical limits for plot
  ylim(c(0,20)) +
  # make it a classic theme - more legible
  theme_classic() +
  # add text to plot
  geom_text(data = sig_levels_locations,
            # make bold
            fontface = "bold",
            # define where labels should go
            aes(x = Location, 
                # define height of label
                y = 4, 
                # what are the labels?
                label = paste0(significance))) +
  xlab("Location") +
  ylab("Mean") +
  # remove legend - not needed here
  theme(legend.position = "none",
        # make label text vertical, easier to read
        axis.text.x = element_text(angle = 90, 
                                   # vertical offset of text
                                   vjust = 0.5, 
                                   # text size
                                   size = 12))
```

Now let's look at Food:

```{r}
# Food

ggplot(gg_data_food, # plot summary data
       # Define plotting - x by group, y is mean, grouping by group
       aes(x = Food, y = mean, group = Food)) +
  # add points to plot for y values
  geom_point() +
  # add error bars around points
  geom_errorbar(data = gg_data_food, 
                # define error bars
                aes(ymin = mean - 2*se, ymax = mean+2*se,
                    # define color, size
                                    color = Food), width = 0.1) +
  # set vertical limits for plot
  ylim(c(0,20)) +
  # make it a classic theme - more legible
  theme_classic() +
  # add text to plot
  geom_text(data = sig_levels_food,
            # make bold
            fontface = "bold",
            # define where labels should go
            aes(x = Food, 
                # define height of label
                y = 4, 
                # what are the labels?
                label = paste0(significance))) +
  xlab("Food") +
  ylab("Mean") +
  # remove legend - not needed here
  theme(legend.position = "none",
        # make label text vertical, easier to read
        axis.text.x = element_text(angle = 90, 
                                   # vertical offset of text
                                   vjust = 0.5, 
                                   # text size
                                   size = 12))
```

AS we can see, we were able to perform an ANOVA on both variables and plot the significant results for both using the data from `aov` and `TukeyHSD`.

### Repeated measures

Now, we are going to do a *repeated measures ANOVA*, where we have the same individuals being measured multiple times. Consider the following imaginary dataset:

```{r}
visits <- c(paste("Visit", 1:3)) %>%
  as.data.frame()

colnames(visits) <- "Visit"

locations <- location %>%
  as.data.frame()

colnames(locations) <- "Locations"

base_data <- cbind(locations, visits) %>%
  expand(Locations, Visit)

Enzyme <- c(5.5,6.2,7.1,4.6,5.2,5.8,4.1,5.2,5.9)

repeated_data <- cbind(base_data, Enzyme)

repeated_data
```

We need to perform the ANOVA again, but we need to account for the factor of which locations are repeated.

```{r}
repeated_aov <- aov(Enzyme ~ factor(Visit) + Error(factor(Locations)), repeated_data)

summary(repeated_aov)
```

Unfortunately, because of the model this is, we cannot perform a Tukey Test on the "object" that is created from this ANOVA analysis. We can, however, approach this from a different direction and get our Tukey results ([thanks to Henrik on StackOverflow!](https://stats.stackexchange.com/questions/14078/post-hoc-test-after-anova-with-repeated-measures-using-r)). **For this to work, we need to install the package**

```{r}
# ensure data is proper format
repeated_data$Locations <- as.factor(repeated_data$Locations)
repeated_data$Visit <- as.factor(repeated_data$Visit)

# fit a linear mixed-effects model
# similar to ANOVA

lme_repeated_data <- lme(Enzyme ~ Visit, 
                         data = repeated_data, 
                         # define repeated section
                         random = ~1|Locations)

# perform ANOVA on model
anova(lme_repeated_data)
```

As we can see above, we can get the ANOVA results from this linear mixed-effects model fit to the dataset. Now, we need to know post-hoc which sets are different:

```{r}
lme_repeated_data %>%
  # "general linear hypothesis"
  # define a comparison to make
  # can add corrections like test = adjusted (type = "bonferroni")
  glht(linfct = mcp(Visit = "Tukey")) %>%
  # return a summary of the above
  summary()
```

We can see that every visit is different.

```{r}
sig_levels_repeated <- matrix(data = c("Visit 1", "A",
                                        "Visit 2", "B",
                                        "Visit 3", "C"), 
                               byrow = T, ncol = 2) %>% as.data.frame() %>%
  cbind(locations)

# make labels match!
colnames(sig_levels_repeated) <- c("Visit", "significance","Locations")

sig_levels_repeated$Visit <- as.factor(sig_levels_repeated$Visit)
```

Let's plot these. *Note* that we are not summarizing these the same way, since things are varying based on individual as well.

*Note*: For reasons I am not certain, you need to put the locations and then `ggplot` uses these colors to define everything. I really don't know why this is happening, so if you have a solution, let me know.

```{r}
ggplot(repeated_data,
       aes(x = Visit, y = Enzyme, colour = Locations)) +
  geom_point(size = 5) +
  # set vertical limits for plot
  ylim(c(0,10)) +
  # offset points
  # show which are overlapping
  geom_jitter(width = 0.1) +
  # make it a classic theme - more legible
  theme_classic() +
  # add text to plot
  geom_text(data = sig_levels_repeated,
            # make bold
            fontface = "bold",
            # define where labels should go
            aes(x = Visit, 
                # define height of label
                y = 2, 
                # what are the labels?
                label = paste0(significance))) +
  xlab("Visits") +
  ylab("Enzyme Measurement") +
  # remove legend - not needed here
  theme(legend.position = "none",
        # make label text vertical, easier to read
        axis.text.x = element_text(angle = 90, 
                                   # vertical offset of text
                                   vjust = 0.5, 
                                   # text size
                                   size = 12))
```

### Factorial ANOVA

Mathematically, a factorial ANOVA is the same as a randomized block ANOVA; please see that section for information on how to run this test.

### ANOVA with interaction

Sometimes when we running a model, we want to look for *interactive effects*. Interactive effects are situations where one (or both) variables on their own do not effect the data, but there is a cumulative effect between variables that effects things. Let's look at an example, based on our initial example but with the data altered.

```{r}
set.seed(8675309)

# average fish size in relation to location in Iceland and food used

location <- c("Tálknafjörður", "Bíldudalur", "Þingeyri")

food <- c("SuperFood", "Gigachad Fish Food", "MegaFish Flakes")

fish_sizes <- c(9.1,8.7,9.6,
                9.4,9.5,8.3,
                8.7,12,9.2)

data_expanded <- matrix(data = fish_sizes, ncol = 3, byrow = TRUE)

rownames(data_expanded) <- location

colnames(data_expanded) <- food

data_expanded
```

```{r}
# create some pseudorandom data
data_expanded2 <- data_expanded - 0.75
data_expanded3 <- data_expanded*1.05

data_expanded <- rbind(data_expanded,
                       data_expanded2,
                       data_expanded3)

# expand to "long" format
data <- data_expanded %>%
  # convert to data frame
  as.data.frame() %>%
  # create new column to account for row names
  # may not be needed, depending on your data format
  mutate(Location = rownames(data_expanded)) %>%
  # !by column for aggregating
  # names_to = what to name column aggregation
  # values_to = what the measurements should be called
  pivot_longer(!Location, names_to = "Food", values_to = "Size")

interactive_aov <- aov(Size ~ Food + Location + Food*Location, data)

summary(interactive_aov)
```

As we can see above, there is a significant effect of `Food`, `Location`, and an *extreme* effect of `Food` interacting with `Location` in the above dataset.

When plotting and performing Tukey tests, you only need to focus on the primary hypotheses for situations like the above. **Note** however, that Tukey gives us our differences and $p$ values for each set of tests and comparisons:

```{r}
TukeyHSD(interactive_aov)
```

## Friedman's test

### By hand

Friedman's test is a non-parametric alternative to a two-way ANOVA, so as you would guess, it can be painful to implement. We will use an altered version of the same test we've used before:

```{r}
# set seed - make reproducible
set.seed(8675309)

# new set of foods - this time, ten of them
food <- c(paste("Food",1:10)) %>%
  as.factor()

# pre-created data frame of locations from earlier
locations2 <- c(paste("Location", 1:10)) %>%
  as.factor()

long_data <- crossing(locations2, food)

long_data$Sizes <- c(runif(n = nrow(long_data) - nrow(long_data)/length(unique(long_data$locations2)),
                           min = 9, max = 12),
                     runif(n = nrow(long_data)/length(unique(long_data$locations2)),
                           min = 11, max = 15)) %>%
  round(1)

long_data
```

Now that we have our expanded and randomized table, we can get started with our test.

First, we have to rank our measurement of interest, averaging the ties.

```{r}
long_data$ranks <- rank(long_data$Sizes, ties.method = "average")

long_data
```

Our calculation for the Friedman's test statistic $Q$ (not to be confused with Tukey's $q$!) is: $$Q = \frac{12}{nk(k+1)} \cdot \Sigma R_j^2 - 3n(k+1)$$

where $n$ is the total number of individuals in each sample in the dataset, $k$ is the number of groups, and $R_j^2$ is the sum of the ranks.

***NOTE***: This section is incomplete, as my by hand answers are varying from what I am calculating using `friedman.test`. Until I resolve the reasons for this difference, this will remain blank.

### Using *R*

As some of you may have guess, this is easier.

```{r}
friedman_long_data <- friedman.test(y = long_data$Sizes,
                                    groups = long_data$food,
                                    blocks = long_data$locations2)

print(friedman_long_data)
```

*Note* you will get a different answer if you are switching the blocks and the groups.

## Homework: Chapter 12

For problems 12.1, 12.2, 12.3, 12.4, and 12.5, state your hypotheses in sentence form and mathematically. Then, identify the appropriate ANOVA and perform the analysis. If you reject the null, complete a Tukey test and plot your results, showing letters denoting each group. **Note** that 12.4 requires a Friedman's test, but all other problems require some form of ANOVA.

Next, for problems 12.7, 12.8, and 12.9, identify the appropriate test and justify your reasoning. State the null and alternative hypothesis in word form and mathematically, and perform your analysis. If you perform an ANOVA *and* you reject the null hypothesis, plot your results and label the groups by letter.

**Remember, only plot the results if you reject your *primary hypothesis*.**
