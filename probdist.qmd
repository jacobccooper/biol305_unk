---
title: "Probability distributions"
author: "Dr. Jacob C. Cooper"
format: html
editor: visual
---

## Probability distributions

```{r,echo=FALSE,message=F}
library(tidyverse)
```

We rely on multiple different probability distributions to help us understand what probable outcomes are for a specific scenario. All of the tests that we are performing are comparing our results to what we would expect under perfectly random scenarios. For example, if we are flipping a coin, we are interested in whether the the observation we have of the flips on our coin matches our expectation given the probability of getting heads or tails on a perfectly fair coin. While it is possible to get all heads or all tails on a coin flip, it is highly unlikely and may lead us to believe we have an unfair coin. The more trails we perform, the more confident we can be that out coin is atypical.

We perform similar comparisons for other distributions. If we are comparing sets of events, we can look at the probability of those events occurring if events are occurring randomly. If we are comparing counts, we can compare our counts to our expectation of counts if events or subjects are distributed randomly throughout the matrix or whether two sets of counts are likely under the same sets of assumptions.

Remember, for our specific tests, we are setting an $\alpha$ value in advance (traditionally $0.05$, or $5$%) against which we compare our $p$ value, with $p$ representing the probability of observing an event *as extreme* or *more extreme* than the event we observe given a specific probability distribution.

Previously, we talked about the [*normal distribution*](https://jacobccooper.github.io/biol305_unk/normality.html), which is used to approximate a lot of datasets in nature. However, several other probability distributions are also useful for biological systems, which are outlined here.

## Binomial distribution

A *binomial distribution* is one in which only two outcomes are possible - often coded as $0$ and $1$ and usually representing failure and success, respectively. The binomial is described by the following function:

$$
p(x)=\binom{n}{x}p^{x}(1-p)^{n-x}
$$

where $n =$ number of trials, $x =$ the number of successes, and $p =$ the probability of a success under random conditions.

In *R*, the binomial distribution is represented by the following functions:

-   `dbinom`: the density of a binomial distribution

-   `pbinom`: the distribution function, or the probability of a specific observation

-   `qbinom`: the value at which a specific probability is found (the *quantile function*)

-   `rbinom`: generates random values according to a binomial.

### Binomial examples

Let's see what this looks like. Let's consider a scenario where we flip a coin 10 times and get 9 heads. How likely is this outcome?

```{r}
x <- pbinom(q = 9, # number successes, 9 heads
            size = 10, # number of trials, 10 flips
            prob = 0.5) # probability with a fair coin

round(x,4)
```

**NOTE** that the trailing $0$ is dropped, such that the real answer is $0.9990$. However, we mentioned before that the $p$ value should be the probability of a result as extreme or more extreme, meaning that it should *always* be less than $0.5$. If we are reporting a value of *greater* than $0.5$, then we are comparing to the upper tail of the distribution. For a one-tailed $\alpha$ of $0.05$, this would mean that we are looking for a value *greater than* $0.95$ ($1-\alpha$).

So, our real $p$ is:

```{r}
1 - round(x,4)
```

Again, the trailing zero is missing. Given that $p < \alpha$, we *reject the null hypothesis* that this is a fair coin.

How does this distribution look?

```{r}
# number of successes
# start at 0 for no heads
x <- 0:10
# cumulative probability to left of outcome
y <- pbinom(x,
            size = 10, 
            prob = 0.5, 
            lower.tail = T)

# cumulative probability of results to the left
plot(x,
     y,
     type="l") # line plot
```

What about if we always have $p$ less than $0.5$ to reflect two tails?

```{r}
# any value greater than 0.5 is subtracted from 1
y[y > 0.5] <- 1 - y[y > 0.5]

plot(x,
     y,
     type="l")
```

What if we do this with a bigger dataset, like for $50$ flips?

```{r}
# number of successes
# start at 0 for no heads
x <- 0:50
# cumulative probability to left of outcome
y <- pbinom(x,
            size = length(x), 
            prob = 0.5, 
            lower.tail = T)

# any value greater than 0.5 is subtracted from 1
y[y > 0.5] <- 1 - y[y > 0.5]

plot(x,
     y,
     type="l")
```

As we increase the number of flips, we can see that the probability of success forms a *normal distribution* centered on the outcome given the default probability. Thus, as we deviate from our *expected outcome* (initial probability multiple by the number of trials), then our results become less likely.

### Binomial exact tests

We can perform exact binomial tests by using the *R* function `binom.test`. This is a built in function within *R*. This test requires the following arguments:

-   `x`: number of successes (success = outcome of interest)

-   `n`: number of trials (number of events)

-   `p`: probability of success in a typical situation (*i.e.*, for a fair coin, this is $50$%)

-   `alternative`: the hypothesis to be tested, whether `two.sided`, `greater`, or `less`.

-   `conf.level` is the *confidence level* to be returned; default is $95$%.

Let's say you flip a coin ten times, randomly assigning one side as a "success" and one side as a "failure". We do ten flips, and get 3 "successes". How likely is this outcome?

```{r}
binom.test(x = 3,   # three successes
           n = 10,  # ten flips
           p = 0.5) # 50% chance on fair coin
```

Now let's say we do 1000 flips, and we get 300 successes.

```{r}
binom.test(x = 300,
           n = 1000,
           p = 0.5)
```

As we can see, both of these return a confidence interval among other things. If we save the object, we can access these "slots" of data using the `$` character.

```{r}
binom_result <- binom.test(x = 3,
                           n = 10,
                           p = 0.5)

binom_result$p.value %>% round(2)
```

```{r}
binom_result$conf.int
```

This test is easily implemented, but always double check and make sure you are setting it up correctly.

## Poisson distribution

The *Poisson distribution* is used to reflect random count data. Specifically, the Poisson is used to determine if success events are *overdispersed* (*i.e.*, regularly spaced), *random*, or *underdispersed* (i.e., *clustered*). The Poisson introduces the variable *lambda* ($\lambda$) which represents the mean ($\mu$) and the variance ($\sigma^2$), which are equal in a Poisson distribution. A Poisson distribution is described by the following function:

$$
p(x)=\frac{\lambda^{x}e^{-\lambda}}{x!}
$$

### Poisson example

The Poisson is represented by the following functions in *R* which closely resemble the functions for the normal and binomial distributions:

-   `dpois`: the log density function

-   `ppois`: log distribution (probability) function

-   `qpois`: quantile function

-   `rpois`: random values from a Poisson.

Let's look at the probability of $0$ to $10$ successes when we have our $\lambda=1$.

```{r}
x <- 0:10
y <- ppois(x,lambda = 1)

# any value greater than 0.5 is subtracted from 1
y[y > 0.5] <- 1 - y[y > 0.5]

plot(x,y,type="l")
```

As we can see, the probability of rare events is high, whereas the probability quickly decreases as the number of successes increases.

### Poisson test

Much like the Binomial Distribution and its `binom.test`, we can use `poisson.test` to analyze data via a Poisson Distribution. This command uses the arguments:

-   `x`: number of events of interest

-   `T`: time base (if for an event count)

-   `r`: hypothesized rate or ratio

-   `alternative` and `conf.level` are the same as for `binom.test`

We will not often use the `poisson.test` in this class, but it is good to be aware of.

## Cumulative Probabilities

With both the Binomial and the Poisson, we can calculate cumulative probabilities. Both of these require the density (`d`) versions of the arguments.

### Binomial cumulative

Let's say we have ten trials with three successes and a base probability of $0.5$. We can calculate the probability to the *left* by using the following:

```{r}
pbinom(q = 3,
       size = 10,
       prob = 0.5)
```

As we can see, this is \~17.19%. Now let's try using `dbinom`. This command gives us the value at an individual bin, given that it is a more discrete distribution for these smaller sample sizes.

```{r}
dbinom(x = 0:3, 
       size = 10, 
       prob = 0.5)
```

Above, we can see the probability of each number of successes three and fewer, for 0, 1, 2, and 3. Let's sum these probabilities.

```{r}
dbinom(x = 0:3, 
       size = 10, 
       prob = 0.5) %>%
  sum()
```

As we can see, we get the same value as for `pbinom`! We can use this method for finding very specific answers, like what is the probability of getting between 3 and 6 successes in ten trials?

```{r}
dbinom(x = 3:6,
       size = 10,
       prob = 0.5) %>% 
  sum() %>% 
  round(4)
```

The probability of getting one of these outcomes is 77.34%.

### Poisson cumulative probability

Likewise, we can use `ppois` to get the $p$ value and `dpois` to get the distribution function of specific outcomes. So, let's say we have a scenario with a $\lambda = 0.5$ and we are looking at the probability of 2 successes or greater. In this case, we have an infinite series, which we can't calculate. However, we can calculate the probability of what it *isn't* and then subtract from 1. In this case, we are looking for the probability of *not* having 0 or 1 successes.

```{r}
dpois(x = 0:1,
      lambda = 0.5)
```

Now, let's sum this and subtract it from 1.

```{r}
1 - dpois(x = 0:1, lambda = 0.5) %>% 
  sum()
```

The probability is only about 9%.

## $\chi^2$-squared distribution

$\chi^2$-squared (pronounced "*kai*", and spelled "*chi*") is a distribution used to understand if count data between different categories matches our expectation. For example, if we are looking at students in the class and comparing major vs. number of books read, we would expect *no association*, however we may find an association for a major such as English which required reading more literature. The $\chi^2$ introduces a new term *degrees of freedom* ($df$) which reflects the number of individuals in the study. For many tests, $df$ are needed to reflect how a distribution changes with respect the number of individuals (and amount of variation possible) within a dataset. The equation for the $\chi^2$ is as follows, with the $\chi^2$ being a special case of the *gamma* ($\gamma$ or $\Gamma$) distribution that is affected by the $df$, which is defined as the number of rows minus one multiplied by the number of columns minus one $df = (rows-1)(cols-1)$:

$$
f_n(x)=\frac{1}{2^{\frac{n}{2}}\Gamma(\frac{n}{2})}x^\frac{n}{2-1}e^\frac{-x}{2}
$$

The $\chi^2$-squared distribution is also represented by the following functions, which perform the same things as the previous outlined equivalents for Poisson and binomial:

-   `dchisq`

-   `pchisq`

-   `qchisq`

-   `rchisq`

We can view these probabilities as well:

```{r}
x <- 0:10

y <- pchisq(x, df = 9)

# any value greater than 0.5 is subtracted from 1
y[y > 0.5] <- 1 - y[y > 0.5]

plot(x,y,type="l")
```

### Calculating the test statistic

We evaluate $\chi^2$ tests by calculating a $\chi^2$ value based on our data and comparing it to an expected $\chi^2$ distribution. This *test statistic* can be evaluated by looking at a $\chi^2$ table or by using *R*. **Note** that you need to know the degrees of freedom in order to properly evaluate a $\chi^2$ test. We calculate our test statistic as follows:

$$
\chi^2=\Sigma\frac{(o-e)^2}{e}
$$

where $e =$ the number of expected individuals and $o =$ the number of observed individuals in each category. Since we are squaring these values, we will only have positive values, and thus this will **always be a one-tailed test**.

There are multiple types of $\chi^2$ test, including the following we will cover here:

-   $\chi^2$ Goodness-of-fit test

-   $\chi^2$ test of independence

### $\chi^2$ Goodness-of-fit test

### $\chi^2$ test of independence

Usually when we use a $\chi^2$, we are looking at count data. Let's consider the following hypothetical scenario, comparing experience with *R* between non-biology majors (who, in this theoretical scenario, do not regularly use *R*) and Biology majors who are required to take *R* for this class:

| Major         | *R* experience | No *R* experience |
|---------------|----------------|-------------------|
| *Non-biology* | 3              | 7                 |
| *Biology*     | 9              | 1                 |

: The above table of counts is also known as a **contingency table**. Intuitively, we can see a difference, but we want to perform a statistical test to see just how likely these counts would be if both groups were equally likely. We can calculate this both "by hand" and using built in *R* functions.

#### $\chi^2$ estimations by hand

First, we can enter the data into *R*.

```{r}
data <- matrix(data = c(3,7,9,1), nrow = 2, ncol = 2, byrow = T)

colnames(data) <- c("R", "No R")
rownames(data) <- c("Non-biology", "Biology")

data
```

Next, we need the *observed - expected* values. We determine expected values either through probability ($0.5 \cdot n$ for equal probability for two categories) or via calculating the the expected values (see later section on *expected counts*). In this case, since we are looking at equally likely in each cell, we have an expected matrix as follows:

```{r}
# total datapoints
N <- sum(data)

expected <- matrix(data = c(0.25*N,0.25*N,0.25*N,0.25*N), nrow = 2, ncol = 2, byrow = T)

colnames(expected) <- c("R", "No R")
rownames(expected) <- c("Non-biology", "Biology")

expected
```

Now we need to find our *observed - expected*.

```{r}
o_e <- data - expected

o_e
```

***Note*** that in *R* we can add and subtract matrices, so there's no reason to reformat these data!

Now, we can square these data.

```{r}
o_e2 <- o_e^2

o_e2
```

Next, we take these and divide them by the expected values and then sum those values.

```{r}
chi_matrix <- o_e2/expected

chi_matrix
```

```{r}
sum(chi_matrix)
```

Here, we get a $\chi^2$ value of 8. We can use our handy family functions to determine the probability of this event:

```{r}
pchisq(8, df = 1, lower.tail = F)
```

Here, we get a $p$ value of 0.005.

Alternatively, we can calculate this using *expected counts*. For many situations, we don't know what the baseline probability *should* be, so we calculate the expected counts based on what we do know. Expected counts are calculated as follows:

$$
Exp(x)=\frac{\Sigma(row_x)\cdot\Sigma(col_x)}{N}
$$

where $N$ is the sum of all individuals in the table. For the above example, this would look like this:

```{r}
data_colsums <- colSums(data)
data_rowsums <- rowSums(data)
N <- sum(data)

expected <- matrix(data = c(data_colsums[1]*data_rowsums[1],
                            data_colsums[2]*data_rowsums[1],
                            data_colsums[1]*data_rowsums[2],
                            data_colsums[2]*data_rowsums[2]),
                   nrow = 2, ncol = 2, byrow = T)

# divide by total number
expected <- expected/N

colnames(expected) <- colnames(data)
rownames(expected) <- rownames(data)

expected
```

Here, we can see our expected number are not quite 50/50! this will give us a different result than our previous iteration.

#### $\chi^2$ estimations in *R*

We can calculate this in *R* by entering in the entire table and using `chisq.test`.

```{r}
data <- matrix(data = c(3,7,9,1), nrow = 2, ncol = 2, byrow = T)

colnames(data) <- c("R", "No R")
rownames(data) <- c("Non-biology", "Biology")

data
```

```{r}
chisq.test(data, correct = F)
```

Here, we get $p = 0.006$, which is significant with $\alpha = 0.05$.

**Note** that these values are slightly different. they will be even more different if `correct` is set to `TRUE`. By default, *R*, uses a [Yate's correction for continuity](https://en.wikipedia.org/wiki/Yates's_correction_for_continuity). This accounts for error introduced by comparing the discrete values to a continuous distribution.

```{r}
chisq.test(data)
```

Applying this correction *lowers* the degrees of freedom, and increases the $p$ value, thus making it harder to get $p < \alpha$.

**Note that the Yate's correction is only applied for 2 x 2 contingency tables.**

Given the slight differences in calculation between by hand and what the functions of *R* are performing, *it's important to always show your work*.

## Fisher's exact test

To be completed; involves calculations on smaller datasets.

## Homework

### Chapter 5

### Chapter 7
